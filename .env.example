# ──────────────────────────────────────────────
# SLM Council – Environment Configuration
# Copy to .env and fill in your values
# ──────────────────────────────────────────────

# GCP
GCP_PROJECT_ID=your-gcp-project-id
GCP_REGION=us-central1
GCP_CREDENTIALS_PATH=          # leave blank to use Application Default Credentials

# ── Orchestrator (Vertex AI – Qwen3-Max / 72B) ──
ORCHESTRATOR_ENDPOINT_ID=
ORCHESTRATOR_MODEL_NAME=qwen3-max

# ── Agent Endpoints (Vertex AI Prediction / self-hosted vLLM) ──
RESEARCHER_ENDPOINT=http://localhost:8001/v1
RESEARCHER_MODEL=gemma-3-4b-it

GENERATOR_ENDPOINT=http://localhost:8002/v1
GENERATOR_MODEL=qwen3-coder-4b

DEBUGGER_ENDPOINT=http://localhost:8003/v1
DEBUGGER_MODEL=deepseek-r1-distill-qwen-7b

TESTER_ENDPOINT=http://localhost:8004/v1
TESTER_MODEL=phi-4-mini

# ── Council Settings ──
MAX_REFINEMENT_PASSES=3
CONSENSUS_THRESHOLD=0.8
REQUEST_TIMEOUT_SECS=120

# ── Rate Limiting & Caching ──
MAX_CONCURRENT_AGENT_CALLS=4
ENABLE_REQUEST_CACHE=true
CACHE_TTL_SECS=300

# ── Agent Memory ──
AGENT_MEMORY_WINDOW=3

# ── Synthesis Token Limits ──
SYNTHESIS_MAX_CODE_CHARS=8000
SYNTHESIS_MAX_REPORT_CHARS=4000

# ── Server ──
API_HOST=0.0.0.0
API_PORT=8080
LOG_LEVEL=INFO
LOG_AGENT_IO=false
LOG_MAX_CHARS=3000
